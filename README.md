# Kafka to Hudi Integration with Flink and DBT

## Описание проекта

Этот проект посвящён интеграции потоковых данных из Kafka в хранилище Hudi с использованием Flink и dbt. Он включает инструменты для генерации данных, потоковой обработки и конфигурации окружения для разработки.

### Основные возможности:
- Потоковая обработка данных из нескольких Kafka-топиков с использованием Flink.
- Обработка данных и загрузка результатов в Apache Hudi.
- Конфигурация для локального разработки с использованием Docker и Minio (S3-совместимое хранилище).
- Генерация данных для тестирования и публикация в Kafka.
- Поддержка Flink в рамках dbt-моделей для обработки событийных данных.

## Функционал

1. **Интеграция Kafka → Hudi**  
   Была реализована модель для обработки данных из двух Kafka-топиков (`first_topic` и `second_topic`).  
   Обработанные данные объединяются и сохраняются в Hudi.  

   Конфигурация поддерживает:
   - Потоковые свойства Flink.
   - Хранилище, совместимое с S3 (Minio).

2. **Генерация данных**  
   Скрипт Python генерирует и публикует симулированные данные в Kafka. Используется `multiprocessing` для обработки данных в 2 топиках одновременно. Сценарий включает:
   - Генерацию данных.
   - Настройку Kafka Producer.
   - Публикацию сообщений с учётом обработки ошибок.

3. **Dev Container Setup**  
   Файлы Docker позволяют разворачивать окружение для разработки, включающее:
   - Flink, Python.
   - Minio, Kafka, ZooKeeper.
   - Сторонние библиотеки (`dbt-flink-adapter`, `kafka-python`).

4. **DBT Configuration**  
   Базовая настройка проекта dbt для обработки данных в Kafka. Включает файлы:
   - `dbt_project.yml`
   - `profiles.yml`, настроенные для использования Flink.

5. **Оптимизированный .gitignore**  
   Исключены нежелательные файлы, включая:
   - Конфигурации IntelliJ IDEA (`.idea/`).
   - Логи выполнения (`/logs`).

## Установка и запуск

### Требования
- Docker и docker-compose.
- Kafka и ZooKeeper.
- Python 3.

### Шаги установки:

1. **Клонирование репозитория**:
   ```bash
   git clone <URL-РЕПОЗИТОРИЯ>
   cd <ИМЯ-ПАПКИ>
   ```

2. **Запуск окружения**:
   Используйте `docker-compose`, чтобы развернуть сервисы:
   ```bash
   docker-compose up -d
   ```

3. **Инициализация Minio**:
   Выполните скрипт для создания S3-бакета:
   ```bash
   ./scripts/init_minio.sh
   ```

4. **Запуск генератор данных**:
   ```bash
   python scripts/kafka_data_generator.py
   ```

5. **Настройка DBT и Flink**:
   Укажите настройки в `profiles.yml` и запустите команды dbt:
   ```bash
   dbt run
   ```

## Лицензия

Лицензия MIT (или другая, если применимо).
